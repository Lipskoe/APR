{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "import os\n",
    "import xml.etree.ElementTree as Xet\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from platform import python_version\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.autograd import Variable\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.read_csv('C:\\\\Users\\\\przem\\\\Downloads\\\\data.csv')\n",
    "my_df=my_df.drop(['gender', 'extroverted','age_group','Unnamed: 0','id','stable','conscientious','agreeable'], axis=1)\n",
    "my_df['document'] = my_df['document'].apply(lambda x : x.lower())\n",
    "my_df['document'] = my_df['document'].apply(lambda x : re.sub(\"@[A-Za-z0-9_]+\",\"\", x))\n",
    "my_df['document'] = my_df['document'].apply(lambda x : re.sub(\"#[A-Za-z0-9_]+\",\"\", x))\n",
    "my_df['document'] = my_df['document'].apply(lambda x : re.sub(\"http\\S+\",\"\", x))\n",
    "my_df['document'] = my_df['document'].apply(lambda x : re.sub(\"[()!?]\",\" \", x))\n",
    "my_df['document'] = my_df['document'].apply(lambda x : re.sub(\"\\[.*?\\]\",\" \", x))\n",
    "my_df['document'] = my_df['document'].apply(lambda x : re.sub(\"[^a-z]\",\" \", x))\n",
    "target_feature=my_df['openx']\n",
    "my_df['target']=(target_feature-min(target_feature))/(max(target_feature)-min(target_feature))\n",
    "my_df=my_df.drop(['openx'], axis=1)\n",
    "my_df.rename({'document': 'text'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0.576309\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>things i want for my business cards but are to...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>painters produced their most highly valued wo...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>your new discussion layout is confusing regar...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i never really understood why game environment...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k and       on a gun  fine  but throwing th...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14161</th>\n",
       "      <td>fifty writing tools  quick list   poynter</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14162</th>\n",
       "      <td>video  how to make vietnamese coffee  by highb...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14163</th>\n",
       "      <td>lyx is soooo awesome    finally figured out ho...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14164</th>\n",
       "      <td>impact algorithms  strategies remarkable peopl...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14165</th>\n",
       "      <td>why you re tired   causes of fatigue</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14166 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    target\n",
       "0      things i want for my business cards but are to...  1.000000\n",
       "1       painters produced their most highly valued wo...  1.000000\n",
       "2       your new discussion layout is confusing regar...  1.000000\n",
       "3      i never really understood why game environment...  1.000000\n",
       "4         k and       on a gun  fine  but throwing th...  1.000000\n",
       "...                                                  ...       ...\n",
       "14161      fifty writing tools  quick list   poynter      0.333333\n",
       "14162  video  how to make vietnamese coffee  by highb...  0.333333\n",
       "14163  lyx is soooo awesome    finally figured out ho...  0.333333\n",
       "14164  impact algorithms  strategies remarkable peopl...  0.333333\n",
       "14165            why you re tired   causes of fatigue     0.333333\n",
       "\n",
       "[14166 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14166 entries, 0 to 14165\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   text    14166 non-null  object \n",
      " 1   target  14166 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 221.5+ KB\n"
     ]
    }
   ],
   "source": [
    "my_df.dropna(inplace=True)\n",
    "my_df.reset_index(drop=True,inplace=True)\n",
    "my_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = my_df.text\n",
    "y = my_df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 2000\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import multiprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelize_tweets(tweets,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(TaggedDocument(t.split(), [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x = pd.concat([x_train,x_validation,x_test])\n",
    "all_x_w2v = labelize_tweets(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2020832.27it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_cbow = Word2Vec(sg=0, vector_size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_cbow.build_vocab([x.words for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2022896.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2814214.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2840041.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2356395.42it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2356301.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2833945.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2353595.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2353315.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2835298.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2353222.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2839634.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2029321.71it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2362673.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2805179.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2360514.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2358265.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2840448.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2356862.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2827472.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2353315.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2360795.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2828953.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2359296.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2361640.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2028490.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2026760.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2357610.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2360702.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2358172.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2355834.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_cbow.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_cbow.alpha -= 0.002\n",
    "    model_cbow.min_alpha = model_cbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2365495.28it/s]\n"
     ]
    }
   ],
   "source": [
    "model_sg = Word2Vec(sg=1, vector_size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_sg.build_vocab([x.words for x in tqdm(all_x_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2362203.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2833405.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2833270.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2360795.87it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2358734.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2361077.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2023240.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2362203.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2360420.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2829896.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2835027.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2833270.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2367003.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2360045.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2356395.42it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2840041.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2833000.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2363143.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2829761.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2833270.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2354714.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2825187.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2361828.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2362391.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2355741.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2831514.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2360608.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2835162.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2360420.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 14166/14166 [00:00<00:00, 2362673.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_sg.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_sg.alpha -= 0.002\n",
    "    model_sg.min_alpha = model_sg.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow.save('w2v_model_cbow.word2vec')\n",
    "model_sg.save('w2v_model_sg.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model_cbow = KeyedVectors.load('w2v_model_cbow.word2vec')\n",
    "model_sg = KeyedVectors.load('w2v_model_sg.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7808"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_cbow.wv.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for w in model_cbow.wv.key_to_index.keys():\n",
    "    embeddings_index[w] = np.append(model_cbow.wv[w],model_sg.wv[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=7808)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[81, 30, 2, 1519, 5114, 12, 111, 306, 2039, 2635, 12, 245, 68, 63, 2, 1053],\n",
       " [327, 2040, 8, 5115, 5116, 38, 3098],\n",
       " [2636, 16, 11, 411, 2041, 362]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = []\n",
    "for x in x_train:\n",
    "    length.append(len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (13882, 35)\n"
     ]
    }
   ],
   "source": [
    "x_train_seq = pad_sequences(sequences, maxlen=maxlen)\n",
    "print('Shape of data tensor:', x_train_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,   81,   30,    2,\n",
       "        1519, 5114,   12,  111,  306, 2039, 2635,   12,  245,   68,   63,\n",
       "           2, 1053],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,  327, 2040,    8, 5115, 5116,\n",
       "          38, 3098],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0, 2636,   16,   11,  411,\n",
       "        2041,  362],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0, 1189, 2042, 3879,\n",
       "        7718,  195],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 5117,   13,\n",
       "        1520, 3880,  153,  900, 7719,   57,   56,   31,    3,  781,  281,\n",
       "           2,  240,    7,    2, 1660,    3,   53,    3,    2,  412,    7,\n",
       "           2,   86]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_val = tokenizer.texts_to_sequences(x_validation)\n",
    "x_val_seq = pad_sequences(sequences_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 18100\n",
    "embedding_matrix = np.zeros((num_words, 200))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "434/434 - 3s - loss: 0.0578 - val_loss: 0.0496 - 3s/epoch - 6ms/step\n",
      "Epoch 2/5\n",
      "434/434 - 2s - loss: 0.0496 - val_loss: 0.0502 - 2s/epoch - 5ms/step\n",
      "Epoch 3/5\n",
      "434/434 - 2s - loss: 0.0427 - val_loss: 0.0526 - 2s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "434/434 - 2s - loss: 0.0368 - val_loss: 0.0603 - 2s/epoch - 5ms/step\n",
      "Epoch 5/5\n",
      "434/434 - 2s - loss: 0.0319 - val_loss: 0.0548 - 2s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f02a51ee0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_01 = Sequential()\n",
    "e = Embedding(num_words, 200, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "model_cnn_01.add(e)\n",
    "model_cnn_01.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn_01.add(GlobalMaxPooling1D())\n",
    "model_cnn_01.add(Dense(256, activation='relu'))\n",
    "model_cnn_01.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn_01.compile(loss='mse', optimizer='adam')\n",
    "model_cnn_01.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "434/434 - 21s - loss: 0.0541 - val_loss: 0.0493 - 21s/epoch - 48ms/step\n",
      "Epoch 2/5\n",
      "434/434 - 20s - loss: 0.0337 - val_loss: 0.0563 - 20s/epoch - 47ms/step\n",
      "Epoch 3/5\n",
      "434/434 - 20s - loss: 0.0174 - val_loss: 0.0522 - 20s/epoch - 47ms/step\n",
      "Epoch 4/5\n",
      "434/434 - 20s - loss: 0.0115 - val_loss: 0.0490 - 20s/epoch - 47ms/step\n",
      "Epoch 5/5\n",
      "434/434 - 21s - loss: 0.0084 - val_loss: 0.0543 - 21s/epoch - 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f01bf7a30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_02 = Sequential()\n",
    "e = Embedding(num_words, 200, input_length=maxlen)\n",
    "model_cnn_02.add(e)\n",
    "model_cnn_02.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn_02.add(GlobalMaxPooling1D())\n",
    "model_cnn_02.add(Dense(256, activation='relu'))\n",
    "model_cnn_02.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn_02.compile(loss='mse', optimizer='adam')\n",
    "model_cnn_02.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "434/434 - 22s - loss: 0.0575 - val_loss: 0.0489 - 22s/epoch - 51ms/step\n",
      "Epoch 2/5\n",
      "434/434 - 21s - loss: 0.0450 - val_loss: 0.0463 - 21s/epoch - 47ms/step\n",
      "Epoch 3/5\n",
      "434/434 - 20s - loss: 0.0336 - val_loss: 0.0481 - 20s/epoch - 47ms/step\n",
      "Epoch 4/5\n",
      "434/434 - 20s - loss: 0.0216 - val_loss: 0.0504 - 20s/epoch - 47ms/step\n",
      "Epoch 5/5\n",
      "434/434 - 20s - loss: 0.0144 - val_loss: 0.0506 - 20s/epoch - 46ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f01d975e0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_03 = Sequential()\n",
    "e = Embedding(num_words, 200, weights=[embedding_matrix], input_length=maxlen, trainable=True)\n",
    "model_cnn_03.add(e)\n",
    "model_cnn_03.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
    "model_cnn_03.add(GlobalMaxPooling1D())\n",
    "model_cnn_03.add(Dense(256, activation='relu'))\n",
    "model_cnn_03.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn_03.compile(loss='mse', optimizer='adam')\n",
    "model_cnn_03.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "434/434 - 36s - loss: 0.0664 - val_loss: 0.0582 - 36s/epoch - 83ms/step\n",
      "Epoch 2/5\n",
      "434/434 - 31s - loss: 0.0662 - val_loss: 0.0581 - 31s/epoch - 72ms/step\n",
      "Epoch 3/5\n",
      "434/434 - 31s - loss: 0.0662 - val_loss: 0.0581 - 31s/epoch - 72ms/step\n",
      "Epoch 4/5\n",
      "434/434 - 31s - loss: 0.0662 - val_loss: 0.0581 - 31s/epoch - 71ms/step\n",
      "Epoch 5/5\n",
      "434/434 - 33s - loss: 0.0662 - val_loss: 0.0581 - 33s/epoch - 75ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f01f75c40>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Activation, TimeDistributed\n",
    "\n",
    "lstm1 = Sequential()\n",
    "e=Embedding(num_words, 200, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "lstm1.add(e)\n",
    "lstm1.add(LSTM(units=200))\n",
    "lstm1.add(Dense(2))\n",
    "lstm1.add(Activation('softmax'))\n",
    "lstm1.compile(loss='mse', optimizer='adam')\n",
    "lstm1.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "434/434 - 62s - loss: 0.0662 - val_loss: 0.0581 - 62s/epoch - 144ms/step\n",
      "Epoch 2/5\n",
      "434/434 - 59s - loss: 0.0662 - val_loss: 0.0581 - 59s/epoch - 137ms/step\n",
      "Epoch 3/5\n",
      "434/434 - 59s - loss: 0.0662 - val_loss: 0.0581 - 59s/epoch - 136ms/step\n",
      "Epoch 4/5\n",
      "434/434 - 58s - loss: 0.0662 - val_loss: 0.0581 - 58s/epoch - 134ms/step\n",
      "Epoch 5/5\n",
      "434/434 - 58s - loss: 0.0662 - val_loss: 0.0581 - 58s/epoch - 134ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f02585c40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm2 = Sequential()\n",
    "e = Embedding(num_words, 200, input_length=maxlen)\n",
    "lstm2.add(e)\n",
    "lstm2.add(LSTM(units=200))\n",
    "lstm2.add(Dense(2))\n",
    "lstm2.add(Activation('softmax'))\n",
    "lstm2.compile(loss='mse', optimizer='adam')\n",
    "lstm2.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "434/434 - 62s - loss: 0.0664 - val_loss: 0.0581 - 62s/epoch - 143ms/step\n",
      "Epoch 2/5\n",
      "434/434 - 60s - loss: 0.0662 - val_loss: 0.0581 - 60s/epoch - 138ms/step\n",
      "Epoch 3/5\n",
      "434/434 - 54s - loss: 0.0662 - val_loss: 0.0581 - 54s/epoch - 123ms/step\n",
      "Epoch 4/5\n",
      "434/434 - 49s - loss: 0.0662 - val_loss: 0.0581 - 49s/epoch - 112ms/step\n",
      "Epoch 5/5\n",
      "434/434 - 48s - loss: 0.0662 - val_loss: 0.0581 - 48s/epoch - 111ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f06843940>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm3 = Sequential()\n",
    "e = Embedding(num_words, 200, weights=[embedding_matrix], input_length=maxlen, trainable=True)\n",
    "lstm3.add(e)\n",
    "lstm3.add(LSTM(units=200))\n",
    "lstm3.add(Dense(2))\n",
    "lstm3.add(Activation('softmax'))\n",
    "lstm3.compile(loss='mse', optimizer='adam')\n",
    "lstm3.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0592\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0556\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0620\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0763\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0763\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "results=[]\n",
    "models=[model_cnn_01,model_cnn_02,model_cnn_03,lstm1,lstm2,lstm3]\n",
    "for m in models:\n",
    "    m.evaluate(x=x_test_seq, y=y_test)\n",
    "    sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "    x_test_seq = pad_sequences(sequences_test, maxlen=maxlen)\n",
    "    y_pred=m.predict(x_test_seq)\n",
    "    corr_y_pred=[]\n",
    "    for i in y_pred:\n",
    "        corr_y_pred.append(i[0])\n",
    "    rms = mean_squared_error(y_test, corr_y_pred, squared=False)\n",
    "    results.append(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24325999158246783,\n",
       " 0.23574411228558845,\n",
       " 0.24901063811607702,\n",
       " 0.2758464476557353,\n",
       " 0.27620934328313484,\n",
       " 0.27649455033626213]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncnn1: word2vec embdedding + not trainable during fitting\\ncnn2: default embdedding\\ncnn2: word2vec embdedding + trainable during fitting\\n============================\\nEXTROVERTED <-0.3, 0.2)=0 <0.2, 0.5>=1:\\n\\ncnn1:  0.6127\\ncnn2:  0.5352\\ncnn3:  0.6408\\nlstm1: 0.6408\\nlstm2: 0.5704\\nlstm3: 0.5775\\n\\n[0.20138032381716772,\\n 0.19798711781557132,\\n 0.1940063193601567,\\n 0.23499138675457792,\\n 0.23476451093520545,\\n 0.23466479625314993]\\n\\nlonger embedding training:\\ncnn1:  0.6127\\ncnn2:  0.6056\\ncnn3:  0.5915\\nlstm1: 0.6127\\nlstm2: 0.5845\\nlstm2: 0.6268\\n============================\\nSTABLE <-0.3, 0.2)=0 <0.2, 0.5>=1:\\n\\ncnn1:  0.6056\\ncnn2:  0.6408\\ncnn3:  0.6972\\nlstm1: 0.6620\\nlstm2: 0.6197\\nlstm3: 0.6690\\n\\n[0.2686938000036717,\\n 0.2672315995209581,\\n 0.2842348235240765,\\n 0.2866351047569809,\\n 0.2865176773619274,\\n 0.28638524453048186]\\n\\nlonger embedding training:\\ncnn1:  0.6761\\ncnn2:  0.6408\\ncnn3:  0.6338\\nlstm1: 0.6620\\nlstm2: 0.6761\\nlstm3: 0.7042\\n============================\\nOPEN:\\nlonger embedding training:\\ncnn1:  0.6408\\ncnn2:  0.6268\\ncnn3:  0.6901\\nlstm1: 0.6408\\nlstm2: 0.6197\\nlstm3: 0.6479\\n============================\\nAGREE <-0.3, 0.2)=0 <0.2, 0.5>=1:\\ncnn1:  0.6268\\ncnn2:  0.5775\\ncnn3:  0.6549\\nlstm1: 0.6479\\nlstm2: 0.5704\\nlstm3: 0.6268\\n\\n[0.19355836347180352,\\n 0.22527534064781957,\\n 0.21643586639481258,\\n 0.20851660443425266,\\n 0.20821464797410172,\\n 0.20789164186216755]\\n \\nlong: \\n\\n[0.2053475517597845,\\n 0.2095479160307962,\\n 0.21552693749754215,\\n 0.2081375504001792,\\n 0.2082030353493711,\\n 0.20819815804562516]\\n\\n============================\\nConsc <-0.2, 0.2)=0 <0.2, 0.5>=1:\\ncnn1:  0.6056\\ncnn2:  0.6408\\ncnn3:  0.6127\\nlstm1: 0.6197\\nlstm2: 0.6127\\nlstm3: 0.6268\\n\\n[0.19135943288621196,\\n 0.20505606298317522,\\n 0.21620428965986255,\\n 0.2046760013249673,\\n 0.20467790279067985,\\n 0.20462718169507244]\\n\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cnn1: word2vec embdedding + not trainable during fitting\n",
    "cnn2: default embdedding\n",
    "cnn2: word2vec embdedding + trainable during fitting\n",
    "\n",
    "REGRESSION:\n",
    "\n",
    "EXTROVERTED\n",
    "\n",
    "cnn1:  0.20138032381716772\n",
    "cnn2:  0.19798711781557132\n",
    "cnn3:  0.1940063193601567\n",
    "lstm1: 0.23499138675457792\n",
    "lstm2: 0.23476451093520545\n",
    "lstm3: 0.23466479625314993\n",
    "\n",
    "STABLE\n",
    "\n",
    "cnn1:  0.2686938000036717\n",
    "cnn2:  0.2672315995209581\n",
    "cnn3:  0.2842348235240765\n",
    "lstm1: 0.2866351047569809\n",
    "lstm2: 0.2865176773619274\n",
    "lstm3: 0.28638524453048186\n",
    "\n",
    "OPEN: \n",
    "\n",
    "cnn1:  0.24325999158246783\n",
    "cnn2:  0.23574411228558845\n",
    "cnn3:  0.24901063811607702\n",
    "lstm1: 0.2758464476557353\n",
    "lstm2: 0.27620934328313484\n",
    "lstm3: 0.27649455033626213\n",
    "\n",
    "AGREEABLE:\n",
    "\n",
    "cnn1:  0.19355836347180352\n",
    "cnn2:  0.22527534064781957\n",
    "cnn3:  0.21643586639481258\n",
    "lstm1: 0.20851660443425266\n",
    "lstm2: 0.20821464797410172\n",
    "lstm3: 0.20789164186216755\n",
    "\n",
    "CONSCIENTIOUS:\n",
    "\n",
    "cnn1:  0.19135943288621196\n",
    "cnn2:  0.20505606298317522\n",
    "cnn3:  0.21620428965986255\n",
    "lstm1: 0.2046760013249673\n",
    "lstm2: 0.20467790279067985\n",
    "lstm3: 0.20462718169507244\n",
    "\n",
    "\n",
    "============================\n",
    "============================\n",
    "CLASSIFICATION:\n",
    "\n",
    "EXTROVERTED <-0.3, 0.2)=0 <0.2, 0.5>=1:\n",
    "\n",
    "cnn1:  0.6127\n",
    "cnn2:  0.5352\n",
    "cnn3:  0.6408\n",
    "lstm1: 0.6408\n",
    "lstm2: 0.5704\n",
    "lstm3: 0.5775\n",
    "\n",
    "============================\n",
    "STABLE <-0.3, 0.2)=0 <0.2, 0.5>=1:\n",
    "\n",
    "cnn1:  0.6056\n",
    "cnn2:  0.6408\n",
    "cnn3:  0.6972\n",
    "lstm1: 0.6620\n",
    "lstm2: 0.6197\n",
    "lstm3: 0.6690\n",
    "\n",
    "============================\n",
    "OPEN:\n",
    "\n",
    "cnn1:  0.6408\n",
    "cnn2:  0.6268\n",
    "cnn3:  0.6901\n",
    "lstm1: 0.6408\n",
    "lstm2: 0.6197\n",
    "lstm3: 0.6479\n",
    "\n",
    "============================\n",
    "AGREE <-0.3, 0.2)=0 <0.2, 0.5>=1:\n",
    "\n",
    "cnn1:  0.6268\n",
    "cnn2:  0.5775\n",
    "cnn3:  0.6549\n",
    "lstm1: 0.6479\n",
    "lstm2: 0.5704\n",
    "lstm3: 0.6268\n",
    "\n",
    "============================\n",
    "CONSCIENTIOUS <-0.2, 0.2)=0 <0.2, 0.5>=1:\n",
    "\n",
    "cnn1:  0.6056\n",
    "cnn2:  0.6408\n",
    "cnn3:  0.6127\n",
    "lstm1: 0.6197\n",
    "lstm2: 0.6127\n",
    "lstm3: 0.6268\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
